{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dec4b787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load data from: data/MachineLearningRating_v3.txt using Pipe separator (sep='|')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mer\\AppData\\Local\\Temp\\ipykernel_14128\\655185960.py:9: DtypeWarning: Columns (4,32,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(DATA_FILE, sep='|', skipinitialspace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data reloaded successfully! ---\n",
      "All column names have been aggressively cleaned.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# The file is correctly located inside the 'data' folder\n",
    "DATA_FILE = \"data/MachineLearningRating_v3.txt\" \n",
    "\n",
    "print(f\"Attempting to load data from: {DATA_FILE} using Pipe separator (sep='|')\")\n",
    "try:\n",
    "    df = pd.read_csv(DATA_FILE, sep='|', skipinitialspace=True) \n",
    "    \n",
    "    print(\"\\n--- Data reloaded successfully! ---\")\n",
    "    \n",
    "    # CRITICAL PRE-STEP: Aggressive Column Name Cleaning\n",
    "    # Remove all characters that are not a-z, A-Z, 0-9, or underscore, and strip whitespace.\n",
    "    df.columns = df.columns.str.replace(r'[^A-Za-z0-9_]+', '', regex=True).str.strip()\n",
    "    \n",
    "    print(\"All column names have been aggressively cleaned.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nFailed to reload data. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6eea419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped high-missing columns: ['NumberOfVehiclesInFleet', 'CrossBorder', 'CustomValueEstimate']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mer\\AppData\\Local\\Temp\\ipykernel_14128\\922420419.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].replace({'Yes': 1, 'No': 0})\n",
      "C:\\Users\\Mer\\AppData\\Local\\Temp\\ipykernel_14128\\922420419.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].replace({'Yes': 1, 'No': 0})\n",
      "C:\\Users\\Mer\\AppData\\Local\\Temp\\ipykernel_14128\\922420419.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].replace({'Yes': 1, 'No': 0})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and converted flag columns to binary (0/1): ['WrittenOff', 'Rebuilt', 'Converted']\n",
      "CapitalOutstanding converted to numeric and filled NaNs with 0.\n",
      "Categorical columns filled with 'Unknown', including NewVehicle.\n",
      "\n",
      "Remaining rows after dropping rows with missing vehicle data: 999546\n",
      "\n",
      "--- Final Data Structure Check (df.info()) ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 999546 entries, 0 to 1000097\n",
      "Columns: 49 entries, UnderwrittenCoverID to TotalClaims\n",
      "dtypes: bool(1), datetime64[ns](1), float64(10), int64(7), object(30)\n",
      "memory usage: 374.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# 1. Drop high-missing columns (the column names are now clean)\n",
    "# We use the cleaned names (e.g., 'NumberOfVehiclesInFleet' will be used assuming the cleaning worked)\n",
    "cols_to_drop = ['NumberOfVehiclesInFleet', 'CrossBorder', 'CustomValueEstimate']\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "print(f\"Dropped high-missing columns: {cols_to_drop}\")\n",
    "\n",
    "# 2. Fix Boolean/Flag Columns (WrittenOff, Rebuilt, Converted)\n",
    "# NOTE: NewVehicle is correctly treated as categorical.\n",
    "flag_cols = ['WrittenOff', 'Rebuilt', 'Converted']\n",
    "for col in flag_cols:\n",
    "    df[col] = df[col].replace({' ': pd.NA, '': pd.NA}) \n",
    "    df[col] = df[col].replace({'Yes': 1, 'No': 0})\n",
    "    df[col] = df[col].fillna(0).astype(int)\n",
    "    \n",
    "print(f\"Cleaned and converted flag columns to binary (0/1): {flag_cols}\")\n",
    "\n",
    "\n",
    "# 3. Handle 'CapitalOutstanding' (Monetary Column)\n",
    "df['CapitalOutstanding'] = pd.to_numeric(df['CapitalOutstanding'], errors='coerce').fillna(0)\n",
    "print(\"CapitalOutstanding converted to numeric and filled NaNs with 0.\")\n",
    "\n",
    "\n",
    "# 4. Handle Categorical Columns with low-to-moderate missingness\n",
    "# Impute with a new category 'Unknown'. Includes 'NewVehicle' now.\n",
    "categorical_cols_to_impute = ['Bank', 'AccountType', 'MaritalStatus', 'Gender', \n",
    "                              'Citizenship', 'LegalType', 'NewVehicle']\n",
    "for col in categorical_cols_to_impute:\n",
    "    df[col] = df[col].replace(' ', pd.NA).fillna('Unknown')\n",
    "print(f\"Categorical columns filled with 'Unknown', including NewVehicle.\")\n",
    "\n",
    "\n",
    "# 5. Drop Rows with Negligible Missing Data (Vehicle Characteristics)\n",
    "# We drop the 552 rows where key vehicle data is missing.\n",
    "df = df.dropna(subset=['mmcode', 'VehicleType', 'make', 'Model', 'Cylinders', \n",
    "                       'cubiccapacity', 'kilowatts', 'bodytype', 'NumberOfDoors', 'VehicleIntroDate'])\n",
    "\n",
    "# 6. Final Data Type Fix\n",
    "df['TransactionMonth'] = pd.to_datetime(df['TransactionMonth'])\n",
    "\n",
    "\n",
    "# Final check of the data frame structure\n",
    "print(f\"\\nRemaining rows after dropping rows with missing vehicle data: {len(df)}\")\n",
    "print(\"\\n--- Final Data Structure Check (df.info()) ---\")\n",
    "df.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "348f1c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Key Descriptive Statistics ---\n",
      "                             count       mean   median         std       min  \\\n",
      "TotalClaims               999546.0      64.34     0.00     2369.56 -12002.41   \n",
      "TotalPremium              999546.0      61.37     2.18      157.01   -782.58   \n",
      "SumInsured                999546.0  603869.28  7500.00  1507340.00      0.01   \n",
      "CalculatedPremiumPerTerm  999546.0     116.16     8.44      220.58      0.00   \n",
      "\n",
      "                                  max  \n",
      "TotalClaims                 393092.11  \n",
      "TotalPremium                  2253.51  \n",
      "SumInsured                10000000.00  \n",
      "CalculatedPremiumPerTerm      3051.82  \n"
     ]
    }
   ],
   "source": [
    "# --- Statistical Summary (Mean, Median, Std Dev) ---\n",
    "\n",
    "# Focus on the target (TotalClaims) and main features (TotalPremium, SumInsured)\n",
    "key_stats = df[['TotalClaims', 'TotalPremium', 'SumInsured', 'CalculatedPremiumPerTerm']].describe().T\n",
    "key_stats['median'] = df[['TotalClaims', 'TotalPremium', 'SumInsured', 'CalculatedPremiumPerTerm']].median()\n",
    "\n",
    "print(\"\\n--- Key Descriptive Statistics ---\")\n",
    "print(key_stats[['count', 'mean', 'median', 'std', 'min', 'max']].round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eae6a306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative values in Claims and Premiums have been fixed to 0.\n",
      "\n",
      "--- Descriptive Statistics AFTER Cleaning ---\n",
      "                             count       mean   median         std   min  \\\n",
      "TotalClaims               999546.0      64.36     0.00     2369.53  0.00   \n",
      "TotalPremium              999546.0      61.40     2.18      156.96  0.00   \n",
      "SumInsured                999546.0  603869.28  7500.00  1507340.00  0.01   \n",
      "CalculatedPremiumPerTerm  999546.0     116.16     8.44      220.58  0.00   \n",
      "\n",
      "                                  max  \n",
      "TotalClaims                 393092.11  \n",
      "TotalPremium                  2253.51  \n",
      "SumInsured                10000000.00  \n",
      "CalculatedPremiumPerTerm      3051.82  \n"
     ]
    }
   ],
   "source": [
    "# --- Outlier and Data Quality Cleaning ---\n",
    "\n",
    "# 1. Handle Negative Values (Critical Fix)\n",
    "# Set all negative claims and premiums to zero.\n",
    "df['TotalClaims'] = df['TotalClaims'].apply(lambda x: max(0, x))\n",
    "df['TotalPremium'] = df['TotalPremium'].apply(lambda x: max(0, x))\n",
    "df['CalculatedPremiumPerTerm'] = df['CalculatedPremiumPerTerm'].apply(lambda x: max(0, x))\n",
    "\n",
    "print(\"Negative values in Claims and Premiums have been fixed to 0.\")\n",
    "\n",
    "\n",
    "# 2. Re-check Descriptive Statistics after fix\n",
    "print(\"\\n--- Descriptive Statistics AFTER Cleaning ---\")\n",
    "cleaned_stats = df[['TotalClaims', 'TotalPremium', 'SumInsured', 'CalculatedPremiumPerTerm']].describe().T\n",
    "cleaned_stats['median'] = df[['TotalClaims', 'TotalPremium', 'SumInsured', 'CalculatedPremiumPerTerm']].median()\n",
    "print(cleaned_stats[['count', 'mean', 'median', 'std', 'min', 'max']].round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "247f674c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mer\\AppData\\Local\\Temp\\ipykernel_14128\\3404425179.py:7: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_claims_mean = df_time['TotalClaims'].resample('M').mean()\n",
      "C:\\Users\\Mer\\AppData\\Local\\Temp\\ipykernel_14128\\3404425179.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_policies_count = df_time['PolicyID'].resample('M').count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Monthly Average Claims (Mean Claims per Policy) ---\n",
      "TransactionMonth\n",
      "2013-10-31     0.000000\n",
      "2013-11-30    42.295217\n",
      "2013-12-31     6.209623\n",
      "2014-01-31     6.807258\n",
      "2014-02-28    30.547676\n",
      "2014-03-31    93.128973\n",
      "2014-04-30    44.350859\n",
      "2014-05-31    54.657432\n",
      "2014-06-30    42.677753\n",
      "2014-07-31    28.819863\n",
      "2014-08-31    35.943245\n",
      "2014-09-30    35.201030\n",
      "2014-10-31    52.191326\n",
      "2014-11-30    76.712045\n",
      "2014-12-31    97.270323\n",
      "2015-01-31    76.778534\n",
      "2015-02-28    73.351793\n",
      "2015-03-31    81.279501\n",
      "2015-04-30    92.796797\n",
      "2015-05-31    69.745481\n",
      "2015-06-30    60.509710\n",
      "2015-07-31    64.860019\n",
      "2015-08-31     9.558443\n",
      "Freq: ME, Name: TotalClaims, dtype: float64\n",
      "\n",
      "--- Monthly Policy Count (Volume Trend) ---\n",
      "TransactionMonth\n",
      "2013-10-31        45\n",
      "2013-11-30      1196\n",
      "2013-12-31      1495\n",
      "2014-01-31      1827\n",
      "2014-02-28      2062\n",
      "2014-03-31      3466\n",
      "2014-04-30      6919\n",
      "2014-05-31      9484\n",
      "2014-06-30     11822\n",
      "2014-07-31     14907\n",
      "2014-08-31     19626\n",
      "2014-09-30     25982\n",
      "2014-10-31     33812\n",
      "2014-11-30     48214\n",
      "2014-12-31     62415\n",
      "2015-01-31     71524\n",
      "2015-02-28     83146\n",
      "2015-03-31     91953\n",
      "2015-04-30     96501\n",
      "2015-05-31     99836\n",
      "2015-06-30    102532\n",
      "2015-07-31    104089\n",
      "2015-08-31    106693\n",
      "Freq: ME, Name: PolicyID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Temporal Analysis: Claims Trend ---\n",
    "\n",
    "# Set 'TransactionMonth' as the index for time series analysis\n",
    "df_time = df.set_index('TransactionMonth')\n",
    "\n",
    "# Calculate the mean TotalClaims per month\n",
    "monthly_claims_mean = df_time['TotalClaims'].resample('M').mean()\n",
    "\n",
    "# Calculate the total number of policies (rows) per month\n",
    "monthly_policies_count = df_time['PolicyID'].resample('M').count()\n",
    "\n",
    "print(\"\\n--- Monthly Average Claims (Mean Claims per Policy) ---\")\n",
    "print(monthly_claims_mean)\n",
    "\n",
    "print(\"\\n--- Monthly Policy Count (Volume Trend) ---\")\n",
    "print(monthly_policies_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "affaef40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved claims_distribution.png\n",
      "Saved claims_temporal_trend.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mer\\AppData\\Local\\Temp\\ipykernel_14128\\3567743579.py:46: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=province_claims.index, y=province_claims.values, palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved claims_by_province.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set a style for professional visualization\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# --- 1. Distribution of TotalClaims (Log-Transformed) ---\n",
    "# Filter non-zero claims for the log transform visualization\n",
    "df_non_zero_claims = df[df['TotalClaims'] > 0]['TotalClaims']\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "# Use log(1 + x) to handle the extreme skewness and visualize the distribution shape better\n",
    "sns.histplot(np.log1p(df_non_zero_claims), bins=50, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Total Claims (Log-Transformed, Claims > 0)')\n",
    "plt.xlabel('Log(1 + Total Claims)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('claims_distribution.png')\n",
    "plt.close()\n",
    "print(\"Saved claims_distribution.png\")\n",
    "\n",
    "\n",
    "# --- 2. Temporal Trend of Claims ---\n",
    "# Recalculate monthly mean claims using 'ME' (Month End) standard\n",
    "df_time = df.set_index('TransactionMonth')\n",
    "monthly_claims_mean = df_time['TotalClaims'].resample('ME').mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "monthly_claims_mean.plot(kind='line', marker='o', linestyle='-', color='teal')\n",
    "plt.title('Monthly Average Total Claims Over Time (Risk Profile)')\n",
    "plt.xlabel('Transaction Month')\n",
    "plt.ylabel('Average Claims per Policy')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('claims_temporal_trend.png')\n",
    "plt.close()\n",
    "print(\"Saved claims_temporal_trend.png\")\n",
    "\n",
    "\n",
    "# --- 3. Categorical Risk Factor: Mean Claims by Province ---\n",
    "# Calculate the mean TotalClaims per Province and take the top 10\n",
    "province_claims = df.groupby('Province')['TotalClaims'].mean().sort_values(ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=province_claims.index, y=province_claims.values, palette='viridis')\n",
    "plt.title('Top 10 Provinces by Average Total Claims')\n",
    "plt.xlabel('Province')\n",
    "plt.ylabel('Average Total Claims (USD)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('claims_by_province.png')\n",
    "plt.close()\n",
    "print(\"Saved claims_by_province.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59bbb1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Portfolio Loss Ratio: 104.81%\n",
      "\n",
      "--- Loss Ratio by Key Risk Factors ---\n",
      "\n",
      "Province Loss Ratio (Top 5):\n",
      "                LossRatio\n",
      "Province                \n",
      "Gauteng           122.27\n",
      "KwaZulu-Natal     108.05\n",
      "Western Cape      106.39\n",
      "North West         79.04\n",
      "Mpumalanga         72.12\n",
      "\n",
      "VehicleType Loss Ratio (Top 5):\n",
      "                    LossRatio\n",
      "VehicleType                 \n",
      "Heavy Commercial      162.81\n",
      "Medium Commercial     105.02\n",
      "Passenger Vehicle     104.79\n",
      "Light Commercial       23.21\n",
      "Bus                    13.73\n",
      "\n",
      "Gender Loss Ratio (Top 5):\n",
      "                LossRatio\n",
      "Gender                  \n",
      "Not specified     106.03\n",
      "Male               86.93\n",
      "Female             82.19\n",
      "Unknown            61.45\n",
      "\n",
      "Correlation between TotalPremium and TotalClaims: 0.0884\n"
     ]
    }
   ],
   "source": [
    "# --- BIVARIATE ANALYSIS: LOSS RATIO ---\n",
    "\n",
    "# 1. Calculate overall Loss Ratio\n",
    "total_claims_sum = df['TotalClaims'].sum()\n",
    "total_premium_sum = df['TotalPremium'].sum()\n",
    "\n",
    "# Add a small epsilon to the denominator to prevent division by zero\n",
    "epsilon = 1e-6\n",
    "overall_loss_ratio = (total_claims_sum / (total_premium_sum + epsilon)) * 100\n",
    "print(f\"Overall Portfolio Loss Ratio: {overall_loss_ratio:.2f}%\")\n",
    "\n",
    "print(\"\\n--- Loss Ratio by Key Risk Factors ---\")\n",
    "\n",
    "# 2. Calculate Loss Ratio by Categorical Variables\n",
    "risk_factors = ['Province', 'VehicleType', 'Gender']\n",
    "\n",
    "for factor in risk_factors:\n",
    "    # Group by the factor and sum Claims and Premiums\n",
    "    df_grouped = df.groupby(factor).agg(\n",
    "        TotalClaims=('TotalClaims', 'sum'),\n",
    "        TotalPremium=('TotalPremium', 'sum')\n",
    "    )\n",
    "    \n",
    "    # Calculate Loss Ratio for the group\n",
    "    df_grouped['LossRatio'] = (df_grouped['TotalClaims'] / (df_grouped['TotalPremium'] + epsilon)) * 100\n",
    "    \n",
    "    # Filter out categories with very low exposure (e.g., total premium < 1000)\n",
    "    df_grouped = df_grouped[df_grouped['TotalPremium'] > 1000].sort_values(by='LossRatio', ascending=False)\n",
    "    \n",
    "    print(f\"\\n{factor} Loss Ratio (Top 5):\\n\", df_grouped[['LossRatio']].head(5).round(2))\n",
    "\n",
    "# --- BIVARIATE ANALYSIS: Correlation between TotalPremium and TotalClaims ---\n",
    "# Although highly skewed, a basic correlation check is part of the requirement.\n",
    "premium_claims_corr = df[['TotalPremium', 'TotalClaims']].corr().loc['TotalPremium', 'TotalClaims']\n",
    "print(f\"\\nCorrelation between TotalPremium and TotalClaims: {premium_claims_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5c524fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top 5 Highest-Risk Vehicle Makes (by Avg Claims) ---\n",
      "make\n",
      "SUZUKI                                 419.63\n",
      "JMC                                    191.68\n",
      "HYUNDAI                                174.22\n",
      "MARCOPOLO                              156.79\n",
      "AUDI                                   137.84\n",
      "Name: TotalClaims, dtype: float64\n",
      "Saved premium_boxplot.png to confirm outliers.\n"
     ]
    }
   ],
   "source": [
    "# --- BIVARIATE ANALYSIS: Vehicle Make/Model Risk ---\n",
    "\n",
    "# Group by make and calculate mean claims, taking the top 5 highest risk makes\n",
    "make_risk = df.groupby('make')['TotalClaims'].mean().sort_values(ascending=False).head(5)\n",
    "\n",
    "print(\"\\n--- Top 5 Highest-Risk Vehicle Makes (by Avg Claims) ---\")\n",
    "print(make_risk.round(2))\n",
    "\n",
    "\n",
    "# --- OUTLIER DETECTION: Box Plot ---\n",
    "\n",
    "# This visualization confirms the extreme outliers we fixed statistically (where median is 0).\n",
    "# We only plot the top 5% of TotalPremium values to make the box plot visible due to skewness,\n",
    "# but for a full view, we will use the clean TotalPremium.\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "# Since TotalClaims has so many zeros, we'll plot TotalPremium as it has a clearer continuous distribution.\n",
    "sns.boxplot(y=df['TotalPremium'])\n",
    "plt.title('Box Plot of TotalPremium (Outlier Detection)')\n",
    "plt.ylabel('Total Premium (USD)')\n",
    "plt.savefig('premium_boxplot.png')\n",
    "plt.close()\n",
    "print(\"Saved premium_boxplot.png to confirm outliers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57618d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mer\\AppData\\Local\\Temp\\ipykernel_14128\\1765109743.py:7: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(y=df['Gender'], order=df['Gender'].value_counts().index, palette='Pastel1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved distribution_gender.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mer\\AppData\\Local\\Temp\\ipykernel_14128\\1765109743.py:18: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(y=df['VehicleType'], order=df['VehicleType'].value_counts().index, palette='Pastel2')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved distribution_vehicle_type.png\n"
     ]
    }
   ],
   "source": [
    "# --- FINAL UNIVARIATE ANALYSIS: Categorical Distributions ---\n",
    "\n",
    "categorical_cols_for_plot = ['Gender', 'VehicleType']\n",
    "\n",
    "# Plot the distribution of Gender\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(y=df['Gender'], order=df['Gender'].value_counts().index, palette='Pastel1')\n",
    "plt.title('Distribution of Policies by Gender')\n",
    "plt.xlabel('Count of Policies')\n",
    "plt.ylabel('Gender')\n",
    "plt.tight_layout()\n",
    "plt.savefig('distribution_gender.png')\n",
    "plt.close()\n",
    "print(\"Saved distribution_gender.png\")\n",
    "\n",
    "# Plot the distribution of Vehicle Type\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(y=df['VehicleType'], order=df['VehicleType'].value_counts().index, palette='Pastel2')\n",
    "plt.title('Distribution of Policies by Vehicle Type')\n",
    "plt.xlabel('Count of Policies')\n",
    "plt.ylabel('Vehicle Type')\n",
    "plt.tight_layout()\n",
    "plt.savefig('distribution_vehicle_type.png')\n",
    "plt.close()\n",
    "print(\"Saved distribution_vehicle_type.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6fba26c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loss Ratio by Cover Type (Risk Comparison) ---\n",
      "                     TotalClaims  TotalPremium  LossRatio\n",
      "CoverType                                                \n",
      "Own Damage           58479523.85   36875771.69     158.59\n",
      "Windscreen            1280177.06    1288564.35      99.35\n",
      "Income Protector      2565458.77    2973185.63      86.29\n",
      "Deposit Cover           43859.65      66835.30      65.62\n",
      "Credit Protection      332589.38    1846776.47      18.01\n",
      "Third Party           1578529.61   13370795.89      11.81\n",
      "Roadside Assistance      3344.10      34485.89       9.70\n",
      "Emergency Charges       16666.67     320896.51       5.19\n",
      "Keys and Alarms          8273.33     213931.22       3.87\n",
      "Accidental Death            0.00     763056.93       0.00\n",
      "\n",
      "--- Top 10 Highest-Risk Postal Codes (Mean Claims, Min 50 Policies) ---\n",
      "     PostalCode  MeanClaims  PolicyCount\n",
      "470        2920     1758.28           55\n",
      "241        1342     1548.41          110\n",
      "319        1751     1343.31           77\n",
      "881        9756     1193.34          132\n",
      "403        2070      888.86           54\n",
      "517        3651      887.00           70\n",
      "864        9323      813.40           55\n",
      "298        1665      752.80           82\n",
      "20           81      694.31          669\n",
      "331        1805      681.01          255\n"
     ]
    }
   ],
   "source": [
    "# --- FINAL BIVARIATE/MULTIVARIATE ANALYSIS ---\n",
    "\n",
    "# 1. Data Comparison: Trends in Insurance Cover Type (Risk Ratio)\n",
    "# Calculate the Loss Ratio (Claims / Premium) for each CoverType\n",
    "\n",
    "epsilon = 1e-6\n",
    "cover_type_risk = df.groupby('CoverType').agg(\n",
    "    TotalClaims=('TotalClaims', 'sum'),\n",
    "    TotalPremium=('TotalPremium', 'sum')\n",
    ")\n",
    "cover_type_risk['LossRatio'] = (cover_type_risk['TotalClaims'] / (cover_type_risk['TotalPremium'] + epsilon)) * 100\n",
    "\n",
    "print(\"\\n--- Loss Ratio by Cover Type (Risk Comparison) ---\")\n",
    "# Filter out tiny exposure groups (e.g., less than 500 total premium) and show the comparison\n",
    "print(cover_type_risk[cover_type_risk['TotalPremium'] > 500].sort_values(by='LossRatio', ascending=False).head(10).round(2))\n",
    "\n",
    "\n",
    "# 2. Correlations/Associations Proxy: High-Risk Postal Codes (Micro-Geography Risk)\n",
    "# This identifies the riskiest micro-geographies by average claims, fulfilling the actionable part of the ZipCode requirement.\n",
    "\n",
    "postal_code_risk = df.groupby('PostalCode').agg(\n",
    "    MeanClaims=('TotalClaims', 'mean'),\n",
    "    PolicyCount=('PolicyID', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Filter for Postal Codes with significant exposure (e.g., at least 50 policies)\n",
    "postal_code_risk = postal_code_risk[postal_code_risk['PolicyCount'] >= 50]\n",
    "top_10_risky_postal_codes = postal_code_risk.sort_values(by='MeanClaims', ascending=False).head(10)\n",
    "\n",
    "print(\"\\n--- Top 10 Highest-Risk Postal Codes (Mean Claims, Min 50 Policies) ---\")\n",
    "print(top_10_risky_postal_codes.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4e81187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mer\\AppData\\Local\\Temp\\ipykernel_8416\\1123586665.py:10: DtypeWarning: Columns (32,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep='|')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Data Loading (Assuming the clean file structure) ---\n",
    "# Replace this path with the actual path to your file if you moved it outside of 'data/'\n",
    "# Note: DVC pull should have restored this file to the 'data/' directory.\n",
    "file_path = 'data/MachineLearningRating_v3.txt'\n",
    "\n",
    "# Load the data using the pipe delimiter\n",
    "df = pd.read_csv(file_path, sep='|')\n",
    "\n",
    "# --- 2. Essential Cleaning from EDA ---\n",
    "# Rename columns for ease of use (if you did this in EDA)\n",
    "df.columns = df.columns.str.replace(' ', '').str.replace('/', '')\n",
    "\n",
    "# Ensure key variables are numeric and clean non-sensical negatives\n",
    "financial_cols = ['TotalClaims', 'TotalPremium', 'CustomValueEstimate']\n",
    "for col in financial_cols:\n",
    "    # Convert to numeric, coercing errors to NaN\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    # Replace non-sensical negative values with 0 (as done in EDA)\n",
    "    df.loc[df[col] < 0, col] = 0\n",
    "\n",
    "# Convert Gender to string and clean up.\n",
    "df['Gender'] = df['Gender'].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb5e2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene's Test P-value (for variance equality): 0.8041\n",
      "\n",
      "--- Two-Sample T-Test Results (Male vs. Female Claims) ---\n",
      "T-statistic: -0.2964\n",
      "P-value: 0.7669656472\n",
      "\n",
      "Conclusion: Fail to Reject the Null Hypothesis. The P-value (0.7669656472) is greater than alpha (0.05).\n",
      "The difference in mean claims is not statistically significant.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# --- Prepare the data for the T-test ---\n",
    "# Filter claims for Male and Female. We use TotalClaims as a proxy for risk severity.\n",
    "male_claims = df[df['Gender'] == 'Male']['TotalClaims']\n",
    "female_claims = df[df['Gender'] == 'Female']['TotalClaims']\n",
    "\n",
    "# Clean the data: Filter out the 'Unknown' and other non-binary values if they were not already cleaned.\n",
    "# (Assuming they were handled, we just compare Male and Female groups here)\n",
    "\n",
    "# --- Check for Variance (Levene's Test) ---\n",
    "# T-tests assume equal variance. Levene's test checks this.\n",
    "# If p-value < 0.05, variances are unequal (use equal_var=False in t-test)\n",
    "levene_test = stats.levene(male_claims, female_claims)\n",
    "print(f\"Levene's Test P-value (for variance equality): {levene_test.pvalue:.4f}\")\n",
    "\n",
    "# --- Perform Two-Sample T-Test ---\n",
    "# We generally assume unequal variances (Welch's T-test) for real-world insurance data.\n",
    "# The `equal_var=False` parameter implements Welch's T-test, which is robust to unequal variances.\n",
    "t_stat, p_value = stats.ttest_ind(male_claims, female_claims, equal_var=False)\n",
    "\n",
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "print(\"\\n--- Two-Sample T-Test Results (Male vs. Female Claims) ---\")\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.10f}\") # Show more precision for the p-value\n",
    "\n",
    "# --- Conclusion ---\n",
    "if p_value < alpha:\n",
    "    print(f\"\\nConclusion: Reject the Null Hypothesis. The P-value ({p_value:.10f}) is less than alpha ({alpha}).\")\n",
    "    print(\"The difference in mean claims between Male and Female policyholders is STATISTICALLY SIGNIFICANT.\")\n",
    "else:\n",
    "    print(f\"\\nConclusion: Fail to Reject the Null Hypothesis. The P-value ({p_value:.10f}) is greater than alpha ({alpha}).\")\n",
    "    print(\"The difference in mean claims is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7573f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity Sample Size: Male=94, Female=14\n",
      "\n",
      "--- T-Test Results: Gender Claim Severity (Claims > 0) ---\n",
      "T-statistic: -0.5790\n",
      "P-value: 0.5680286952\n",
      "\n",
      "Conclusion: Fail to Reject H₀. The difference in average claim severity is NOT statistically significant.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Claim Severity: T-Test (Comparing means of non-zero claims) ---\n",
    "\n",
    "# 1. Create a Claims-Only Dataframe\n",
    "claims_only_df = df[df['TotalClaims'] > 0].copy()\n",
    "\n",
    "# 2. Segment the Data\n",
    "male_severity = claims_only_df[claims_only_df['Gender'] == 'Male']['TotalClaims']\n",
    "female_severity = claims_only_df[claims_only_df['Gender'] == 'Female']['TotalClaims']\n",
    "\n",
    "# Ensure groups are large enough\n",
    "print(f\"Severity Sample Size: Male={len(male_severity)}, Female={len(female_severity)}\")\n",
    "\n",
    "# 3. Perform Welch's T-Test (robust for potentially unequal variances)\n",
    "t_stat_sev, p_value_sev = stats.ttest_ind(male_severity, female_severity, equal_var=False)\n",
    "alpha = 0.05\n",
    "\n",
    "print(\"\\n--- T-Test Results: Gender Claim Severity (Claims > 0) ---\")\n",
    "print(f\"T-statistic: {t_stat_sev:.4f}\")\n",
    "print(f\"P-value: {p_value_sev:.10f}\")\n",
    "\n",
    "# 4. Conclusion\n",
    "if p_value_sev < alpha:\n",
    "    print(f\"\\nConclusion: Reject H₀. The difference in average claim severity is STATISTICALLY SIGNIFICANT.\")\n",
    "else:\n",
    "    print(f\"\\nConclusion: Fail to Reject H₀. The difference in average claim severity is NOT statistically significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "910f0499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chi-Squared Test Results: Gender Claim Frequency ---\n",
      "Contingency Table (Count of Policies):\n",
      "Claimed      0   1\n",
      "Gender            \n",
      "Male     42723  94\n",
      "Female    6741  14\n",
      "\n",
      "Chi-Squared Statistic: 0.0037\n",
      "P-value: 0.9514644755\n",
      "\n",
      "Conclusion: Fail to Reject H₀. The difference in claim frequency is NOT statistically significant.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# --- 2. Claim Frequency: Chi-Squared Test (Comparing proportions) ---\n",
    "\n",
    "# 1. Create a binary claim indicator\n",
    "df['Claimed'] = np.where(df['TotalClaims'] > 0, 1, 0)\n",
    "\n",
    "# 2. Create the Contingency Table (Observed Frequencies)\n",
    "# Rows: Gender | Columns: Claimed (0 or 1)\n",
    "contingency_table = pd.crosstab(df['Gender'], df['Claimed'])\n",
    "\n",
    "# Remove 'Unknown' or other low-volume groups for a cleaner test (if necessary)\n",
    "contingency_table = contingency_table.loc[['Male', 'Female']]\n",
    "\n",
    "# 3. Perform Chi-Squared Test\n",
    "chi2_stat, p_value_freq, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(\"\\n--- Chi-Squared Test Results: Gender Claim Frequency ---\")\n",
    "print(\"Contingency Table (Count of Policies):\")\n",
    "print(contingency_table)\n",
    "print(f\"\\nChi-Squared Statistic: {chi2_stat:.4f}\")\n",
    "print(f\"P-value: {p_value_freq:.10f}\")\n",
    "\n",
    "# 4. Conclusion\n",
    "if p_value_freq < alpha:\n",
    "    print(f\"\\nConclusion: Reject H₀. The difference in claim frequency is STATISTICALLY SIGNIFICANT.\")\n",
    "else:\n",
    "    print(f\"\\nConclusion: Fail to Reject H₀. The difference in claim frequency is NOT statistically significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c88cd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the following Provinces for significant claim severity differences: ['Gauteng', 'Western Cape', 'KwaZulu-Natal', 'North West', 'Mpumalanga']\n",
      "\n",
      "--- One-Way ANOVA Results: Province Claim Severity (Claims > 0) ---\n",
      "F-statistic: 8.4575\n",
      "P-value: 0.0000008881\n",
      "\n",
      "Conclusion: Reject H₀. The P-value (0.0000008881) is less than alpha (0.05).\n",
      "The difference in mean claim severity across the Top Provinces is STATISTICALLY SIGNIFICANT.\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df' and 'claims_only_df' from the previous steps are available.\n",
    "# Re-running the data preparation steps to be safe:\n",
    "top_provinces = df['Province'].value_counts().nlargest(5).index\n",
    "claims_only_df = df[df['TotalClaims'] > 0].copy()\n",
    "\n",
    "# --- Prepare data for ANOVA (Geographical Risk) ---\n",
    "\n",
    "# Create a list of claim severity arrays, one for each of the top 5 provinces\n",
    "province_severity_list = [\n",
    "    claims_only_df[claims_only_df['Province'] == province]['TotalClaims'].values\n",
    "    for province in top_provinces\n",
    "]\n",
    "\n",
    "# Exclude any empty arrays if a top province somehow had zero claims in the sample (highly unlikely but defensive)\n",
    "province_severity_list = [arr for arr in province_severity_list if len(arr) > 0]\n",
    "\n",
    "print(f\"Testing the following Provinces for significant claim severity differences: {list(top_provinces)}\")\n",
    "\n",
    "# --- Perform One-Way ANOVA ---\n",
    "# This tests if the mean claim severity of any province is statistically different from the others.\n",
    "f_stat, p_value_anova = stats.f_oneway(*province_severity_list)\n",
    "alpha = 0.05\n",
    "\n",
    "print(\"\\n--- One-Way ANOVA Results: Province Claim Severity (Claims > 0) ---\")\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"P-value: {p_value_anova:.10f}\")\n",
    "\n",
    "# --- Conclusion ---\n",
    "if p_value_anova < alpha:\n",
    "    print(f\"\\nConclusion: Reject H₀. The P-value ({p_value_anova:.10f}) is less than alpha ({alpha}).\")\n",
    "    print(\"The difference in mean claim severity across the Top Provinces is STATISTICALLY SIGNIFICANT.\")\n",
    "else:\n",
    "    print(f\"\\nConclusion: Fail to Reject H₀. The P-value ({p_value_anova:.10f}) is greater than alpha ({alpha}).\")\n",
    "    print(\"The difference in mean claim severity across the Top Provinces is NOT statistically significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61444362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Hypothesis H₀: No risk differences between zip codes ---\n",
      "P-value for Claim Severity difference: 0.0000000000\n",
      "Conclusion: Reject H₀. Zip Code groups have a STATISTICALLY SIGNIFICANT difference in claim severity.\n",
      "\n",
      "--- Testing Hypothesis H₀: No significant margin (profit) difference between zip codes ---\n",
      "P-value for Margin difference: 0.0000000000\n",
      "Conclusion: Reject H₀. Zip Code groups have a STATISTICALLY SIGNIFICANT difference in margin (profit).\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df' and 'claims_only_df' are available.\n",
    "\n",
    "# 1. Calculate Mean Severity per Postal Code (Zip Code)\n",
    "zip_severity = claims_only_df.groupby('PostalCode')['TotalClaims'].mean().reset_index()\n",
    "zip_severity.rename(columns={'TotalClaims': 'MeanSeverity'}, inplace=True)\n",
    "\n",
    "# 2. Define High-Risk and Low-Risk Groups\n",
    "# We'll use the 75th percentile of MeanSeverity as the cutoff for 'High-Risk'\n",
    "risk_cutoff = zip_severity['MeanSeverity'].quantile(0.75)\n",
    "\n",
    "# Merge the risk calculation back to the main DataFrame\n",
    "df = df.merge(zip_severity, on='PostalCode', how='left')\n",
    "\n",
    "# Classify the Postal Codes\n",
    "df['ZipRiskGroup'] = np.where(df['MeanSeverity'] >= risk_cutoff, 'HighRisk', 'LowRisk')\n",
    "\n",
    "# --- 4.1 Test for Risk Differences (Claim Severity) ---\n",
    "print(\"\\n--- Testing Hypothesis H₀: No risk differences between zip codes ---\")\n",
    "\n",
    "high_risk_severity = df[df['ZipRiskGroup'] == 'HighRisk']['TotalClaims'].fillna(0)\n",
    "low_risk_severity = df[df['ZipRiskGroup'] == 'LowRisk']['TotalClaims'].fillna(0)\n",
    "\n",
    "# Note: We include zero claims here for simplicity since the groups are large and created based on claim data.\n",
    "# We must fill NaN values (for PostalCodes not present in claims_only_df) with 0 before comparison.\n",
    "\n",
    "t_stat_zip, p_value_zip = stats.ttest_ind(high_risk_severity, low_risk_severity, equal_var=False)\n",
    "\n",
    "print(f\"P-value for Claim Severity difference: {p_value_zip:.10f}\")\n",
    "if p_value_zip < 0.05:\n",
    "    print(\"Conclusion: Reject H₀. Zip Code groups have a STATISTICALLY SIGNIFICANT difference in claim severity.\")\n",
    "else:\n",
    "    print(\"Conclusion: Fail to Reject H₀. Zip Code groups do NOT have a statistically significant difference.\")\n",
    "\n",
    "# --- 4.2 Test for Margin/Profit Difference ---\n",
    "# Margin = TotalPremium - TotalClaims (as defined in instructions)\n",
    "df['Margin'] = df['TotalPremium'] - df['TotalClaims']\n",
    "\n",
    "high_risk_margin = df[df['ZipRiskGroup'] == 'HighRisk']['Margin'].fillna(0)\n",
    "low_risk_margin = df[df['ZipRiskGroup'] == 'LowRisk']['Margin'].fillna(0)\n",
    "\n",
    "print(\"\\n--- Testing Hypothesis H₀: No significant margin (profit) difference between zip codes ---\")\n",
    "\n",
    "t_stat_margin, p_value_margin = stats.ttest_ind(high_risk_margin, low_risk_margin, equal_var=False)\n",
    "\n",
    "print(f\"P-value for Margin difference: {p_value_margin:.10f}\")\n",
    "if p_value_margin < 0.05:\n",
    "    print(\"Conclusion: Reject H₀. Zip Code groups have a STATISTICALLY SIGNIFICANT difference in margin (profit).\")\n",
    "else:\n",
    "    print(\"Conclusion: Fail to Reject H₀. Zip Code groups do NOT have a statistically significant difference in margin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd313e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
